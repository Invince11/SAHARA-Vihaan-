                                                  SAHARA: Disability is just a word!

A  smart aid made using machine learning, computer vision and raspberry pi. The project proposes a smart stick which is equipped with a raspberry pi, pycam and and ultrasonic sensor with a buzzer. On the side of the handle, three buttons are present, each having a specific function. 

First button automates the camera and detects the objects, the objects description is generated and converted to the speech.  The speech would be heard in a bluetooth ear bud hearing device worn by the user. 

The second button is used to invoke navigation feature. When the button is pressed the user enters his destination through speech and is guided all through the route by voice and object detection help him to move without getting bumped into something.

The third button is used to make a call where user speaks the contacts name or the no and the call will be made. 
All this iot part is handled by the raspberry pi.
 
![Alt text](https://github.com/Invince11/Vihaan-/blob/master/Stick...png)

 The second component which we provide is a smart specs. The specs is equipped with picam which takes image and through computer vision and machine learning technology the image processing is done and the data conveyed by image is transferred to user in form of speech and complete process is supported through  raspberry pi.
Also the specs can be used to implement facial expressions in which persons mood through his expressions will be analysed and will be converted to speech and provided to the user.

![Alt text](https://github.com/Invince11/Vihaan-/blob/master/spec.png)
